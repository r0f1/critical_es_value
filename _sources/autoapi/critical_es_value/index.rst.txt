critical_es_value
=================

.. py:module:: critical_es_value


Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/critical_es_value/corrtest/index
   /autoapi/critical_es_value/linreg/index
   /autoapi/critical_es_value/ttest/index
   /autoapi/critical_es_value/utils/index


Functions
---------

.. autoapisummary::

   critical_es_value.critical_for_correlation_test
   critical_es_value.critical_for_correlation_test_from_values
   critical_es_value.critical_for_linear_regression
   critical_es_value.critical_for_linear_regression_from_values
   critical_es_value.critical_for_one_sample_ttest
   critical_es_value.critical_for_one_sample_ttest_from_values
   critical_es_value.critical_for_two_sample_ttest
   critical_es_value.critical_for_two_sample_ttest_from_values
   critical_es_value.determine_welch_correction
   critical_es_value.get_alpha
   critical_es_value.get_bias_correction_factor_J


Package Contents
----------------

.. py:function:: critical_for_correlation_test(x: numpy.typing.ArrayLike, y: numpy.typing.ArrayLike, confidence: float = 0.95, alternative: str = 'two-sided', variant: str = 'ttest') -> pandas.DataFrame

   Calculate critical effect size values for a pearson correlation test.

   :param x: Sample data for group 1.
   :type x: ArrayLike
   :param y: Sample data for group 2.
   :type y: ArrayLike
   :param confidence: Confidence level between 0 and 1 (exclusive). Default is 0.95.
   :type confidence: float
   :param alternative: The alternative hypothesis. Either "two-sided", "greater", or "less". Default is "two-sided".
   :type alternative: str
   :param variant: The statistical test variant. Either "ttest" or "ztest". Default is "ttest".
   :type variant: str

   :returns:

             A DataFrame with the following columns:
                 - `r`: Pearson correlation coefficient
                 - `n`: Sample size
                 - `dof`: Degrees of freedom
                 - `r_critical`: Critical value for the correlation coefficient
                 - `rz_critical`: Critical value for Fisher's z-transformed correlation coefficient (only for "ztest" variant)
                 - `se_r`: Standard error of the correlation coefficient
                 - `se_r_critical`: Standard error of the critical correlation coefficient
                 - `se_rz_critical`: Standard error of the critical Fisher's z-transformed correlation coefficient (only for "ztest" variant)
   :rtype: pd.DataFrame

   .. rubric:: Examples

   >>> import critical_es_value as cev
   >>> x = [1,2,3,4,5,6]
   >>> y = [2,2,2,3,3,3]
   >>> cev.critical_for_correlation_test(x, y)
             n        r  dof  r_critical      se_r  se_r_critical
   critical  6  0.87831    4    0.811401  0.239046       0.292245


.. py:function:: critical_for_correlation_test_from_values(r: float, n: int, confidence: float = 0.95, alternative: str = 'two-sided', variant: str = 'ttest') -> pandas.DataFrame

   Calculate critical effect size values given pearson correlation coefficient, sample size and significance level.

   :param r: Pearson correlation coefficient.
   :type r: float
   :param n: Sample size.
   :type n: int
   :param confidence: Confidence level between 0 and 1 (exclusive). Default is 0.95.
   :type confidence: float
   :param alternative: The alternative hypothesis. Either "two-sided", "greater", or "
   :type alternative: str
   :param variant: The statistical test variant. Either "ttest" or "ztest". Default is "ttest".
   :type variant: str

   :returns:

             A DataFrame with the following columns:
                 - `r`: Pearson correlation coefficient
                 - `n`: Sample size
                 - `dof`: Degrees of freedom
                 - `r_critical`: Critical value for the correlation coefficient
                 - `rz_critical`: Critical value for Fisher's z-transformed correlation coefficient (only for "ztest" variant)
                 - `se_r`: Standard error of the correlation coefficient
                 - `se_r_critical`: Standard error of the critical correlation coefficient
                 - `se_rz_critical`: Standard error of the critical Fisher's z-transformed correlation coefficient (only for "ztest" variant)
   :rtype: pd.DataFrame

   :raises ValueError: If `variant` is not one of "ttest" or "ztest".

   .. rubric:: Examples

   >>> import pingouin as pg
   >>> import critical_es_value as cev
   >>> x = [1,2,3,4,5,6]
   >>> y = [2,2,2,3,3,3]
   >>> corr = pg.corr(x, y, method="pearson").iloc[0]
   >>> cev.critical_for_correlation_test(x, y)
             n        r  dof  r_critical      se_r  se_r_critical
   critical  6  0.87831    4    0.811401  0.239046       0.292245


.. py:function:: critical_for_linear_regression(X: pandas.DataFrame, y: pandas.Series, confidence: float = 0.95, alternative: str = 'two-sided', variant: str = 'ttest', **kwargs) -> pandas.DataFrame

   Calculate critical effect size values for linear regression coefficients.

   :param X: DataFrame containing the independent variables.
   :type X: pd.DataFrame
   :param y: Series containing the dependent variable.
   :type y: pd.Series
   :param confidence: Confidence level between 0 and 1 (exclusive). Default is 0.95.
   :type confidence: float
   :param alternative: The alternative hypothesis. Either "two-sided", "greater", or "less". Default is "two-sided".
   :type alternative: str
   :param variant: The statistical test variant. Either "ttest" or "ztest". Default is "ttest".
   :type variant: str
   :param \*\*kwargs: Additional keyword arguments to pass to pingouin.linear_regression.

   :returns:

             Returns a DataFrame with the following columns:
                 - `names`: Names of the regression coefficients
                 - `coef`: Estimated regression coefficients
                 - `coef_critical`: Critical value for the regression coefficients
   :rtype: pd.DataFrame

   .. rubric:: Examples

   >>> import pandas as pd
   >>> import critical_es_value as cev
   >>> df = pd.DataFrame({
   ...    "x1": [1,2,3,4,5,6],
   ...    "x2": [2,2,2,3,3,3],
   ...    "y": [3,4,5,6,7,8],
   ... })
   >>> cev.critical_for_linear_regression(df[["x1", "x2"]], df["y"])
          names          coef  coef_critical
   0  Intercept  2.000000e+00   1.082596e-14
   1         x1  1.000000e+00   1.875111e-15
   2         x2  1.527841e-15   6.404723e-15


.. py:function:: critical_for_linear_regression_from_values(coeffs: numpy.typing.ArrayLike, coeffs_se: numpy.typing.ArrayLike, coeffs_names: numpy.typing.ArrayLike, dof: Optional[int] = None, confidence: float = 0.95, alternative: str = 'two-sided', variant: str = 'ttest') -> pandas.DataFrame

   Calculate critical effect size values given linear regression coefficients.

   :param coeffs: Estimated regression coefficients.
   :type coeffs: ArrayLike
   :param coeffs_se: Standard errors of the regression coefficients.
   :type coeffs_se: ArrayLike
   :param coeffs_names: Names of the regression coefficients.
   :type coeffs_names: ArrayLike
   :param dof: Degrees of freedom of the model residuals. Only used for "ttest" variant.
   :type dof: Optional[int]
   :param confidence: Confidence level between 0 and 1 (exclusive). Default is 0.95.
   :type confidence: float
   :param alternative: The alternative hypothesis. Either "two-sided", "greater", or "
   :type alternative: str
   :param variant: The statistical test variant. Either "ttest" or "ztest". Default is "ttest".
   :type variant: str

   :returns: An array containing critical effect size values for each coefficient.
   :rtype: pd.DataFrame

   :raises ValueError: If variant is not one of "ttest" or "ztest".

   .. rubric:: Examples

   >>> import pandas as pd
   >>> import pingouin as pg
   >>> import critical_es_value as cev
   >>> df = pd.DataFrame({
   ...    "x1": [1,2,3,4,5,6],
   ...    "x2": [2,2,2,3,3,3],
   ...    "y": [3,4,5,6,7,8],
   ... })
   >>> model = pg.linear_regression(df[["x1", "x2"]], df["y"])
   >>> cev.critical_for_linear_regression_from_values(
   ...     coeffs=model["coef"].values,
   ...     coeffs_se=model["se"].values,
   ...     coeffs_names=model["names"].values,
   ...     dof=model.df_resid_,
   ...     variant="ttest",
   ... )
          names          coef  coef_critical
   0  Intercept  2.000000e+00   1.082596e-14
   1         x1  1.000000e+00   1.875111e-15
   2         x2  1.527841e-15   6.404723e-15


.. py:function:: critical_for_one_sample_ttest(x: numpy.typing.ArrayLike, confidence: float = 0.95, alternative: str = 'two-sided') -> pandas.DataFrame

   Calculate critical effect size values for a one-sample t-test.

   :param x: Sample data.
   :type x: ArrayLike
   :param confidence: Confidence level between 0 and 1 (exclusive). Default is 0.95.
   :type confidence: float
   :param alternative: The alternative hypothesis. Either "two-sided", "greater", or "less". Default is "two-sided".
   :type alternative: str

   :returns:

             Returns a DataFrame with the following columns:
                 - `T`: t-value of the test statistic
                 - `dof`: Degrees of freedom
                 - `T_critical`: Critical t-value
                 - `d`: Cohen's d
                 - `d_critical`: Critical value for Cohen's d
                 - `g`: Hedges' g
                 - `g_critical`: Critical value for Hedges' g
                 - `b_critical`: Critical value for the raw mean difference
   :rtype: pd.DataFrame

   .. rubric:: Examples

   >>> import critical_es_value as cev
   >>> x = [1,2,3,4,5,6]
   >>> cev.critical_for_one_sample_ttest(x).T
               critical
   T           4.582576
   dof         5.000000
   T_critical  2.570582
   d           1.870829
   d_critical  1.049436
   g           1.572897
   g_critical  0.882312
   b_critical  1.963314


.. py:function:: critical_for_one_sample_ttest_from_values(t: float, n: int, dof: int, confidence: float = 0.95, alternative: str = 'two-sided', std: Optional[float] = None) -> pandas.DataFrame

   Calculate critical effect size values for a one-sample t-test given t, sample size and other parameters.

   :param t: t-value of the test statistic.
   :type t: float
   :param n: Sample size.
   :type n: int
   :param dof: Degrees of freedom.
   :type dof: int
   :param confidence: Confidence level between 0 and 1 (exclusive). Default is 0.95.
   :type confidence: float
   :param alternative: The alternative hypothesis. Either "two-sided", "greater", or "less". Default is "two-sided".
   :type alternative: str
   :param std: Standard deviation of the sample. If None, b_critical will not be calculated. Default is None.
   :type std: Optional[float]

   :returns:

             Returns a DataFrame with the following columns:
                 - `T`: t-value of the test statistic
                 - `dof`: Degrees of freedom
                 - `T_critical`: Critical t-value
                 - `d`: Cohen's d
                 - `d_critical`: Critical value for Cohen's d
                 - `g`: Hedges' g
                 - `g_critical`: Critical value for Hedges' g
                 - `b_critical`: Critical value for the raw mean difference
   :rtype: pd.DataFrame

   .. rubric:: Examples

   >>> import numpy as np
   >>> import pingouin as pg
   >>> import critical_es_value as cev
   >>> x = [1,2,3,4,5,6]
   >>> t_test_result = pg.ttest(x, 0, paired=False).iloc[0]
   >>> cev.critical_for_one_sample_ttest_from_values(
   ...    t=t_test_result["T"],
   ...    n=len(x),
   ...    dof=t_test_result.dof,
   ...    std=np.std(x, ddof=1),
   ... ).T
               critical
   T           4.582576
   dof         5.000000
   T_critical  2.570582
   d           1.870829
   d_critical  1.049436
   g           1.572897
   g_critical  0.882312
   b_critical  1.963314


.. py:function:: critical_for_two_sample_ttest(x: numpy.typing.ArrayLike, y: numpy.typing.ArrayLike, paired: bool = False, correction: Union[bool, str] = 'auto', confidence: float = 0.95, alternative: str = 'two-sided') -> pandas.DataFrame

   Calculate critical effect size values for a paired or an unpaired two-sample t-test.

   :param x: Sample data for group 1.
   :type x: ArrayLike
   :param y: Sample data for group 2.
   :type y: ArrayLike
   :param paired: Whether the samples are paired. Default is False.
   :type paired: bool
   :param correction: For unpaired two sample T-tests, specify whether or not to correct for unequal
                      variances using Welch separate variances T-test. If "auto", it will automatically uses Welch T-test when
                      the sample sizes are unequal. For paired T-tests, this parameter is ignored and no correction is performed.
                      Default is "auto".
   :type correction: Union[bool, str]
   :param confidence: Confidence level between 0 and 1 (exclusive). Default is 0.95.
   :type confidence: float
   :param alternative: The alternative hypothesis. Either "two-sided", "greater", or "less". Default is "two-sided".
   :type alternative: str

   :returns:

             Returns a DataFrame with the following columns:
                - `T`: t-value of the test statistic
                - `dof`: Degrees of freedom
                - `T_critical`: Critical t-value
                - `d`: Cohen's d
                - `d_critical`: Critical value for Cohen's d
                - `g`: Hedges' g
                - `g_critical`: Critical value for Hedges' g
                - `b_critical`: Critical value for the raw mean difference
   :rtype: pd.DataFrame

   :raises ValueError: If for paired tests, lengths of x and y are not equal.

   .. rubric:: Examples

   >>> import critical_es_value as cev
   >>> x = [1,2,3,4,5,6]
   >>> y = [2,2,2,3,3,3]
   >>> cev.critical_for_two_sample_ttest(x, y).T
                critical
   T            1.256562
   dof         10.000000
   T_critical   2.228139
   d            0.725476
   d_critical   1.286417
   g            0.669430
   g_critical   1.187035
   b_critical   1.773203


.. py:function:: critical_for_two_sample_ttest_from_values(t: float, n1: int, n2: int, dof: int, std1: Optional[float] = None, std2: Optional[float] = None, paired: bool = False, r12: Optional[float] = None, correction: Union[bool, str] = 'auto', confidence: float = 0.95, alternative: str = 'two-sided') -> pandas.DataFrame

   Calculate critical effect size values for a paired or an unpaired two-sample t-test given t, sample sizes and other parameters.

   :param t: t-value of the test statistic.
   :type t: float
   :param n1: Sample size of group 1.
   :type n1: int
   :param n2: Sample size of group 2.
   :type n2: int
   :param dof: Degrees of freedom.
   :type dof: int
   :param std1: Standard deviation of group 1. If None, b_critical will not be calculated.
                For paired T-test, the standard deviation of the difference. Default is None.
   :type std1: Optional[float]
   :param std2: Standard deviation of group 2. If None, b_critical will not be calculated.
                For paired T-test, this parameter is ignored. Default is None.
   :type std2: Optional[float]
   :param paired: Whether the samples are paired. Default is False.
   :type paired: bool
   :param r12: For paired T-test, Pearson correlation between the two groups. For unpaired T-test,
               this parameter is ignored. Default is None.
   :type r12: Optional[float]
   :param correction: For unpaired two sample T-tests, specify whether or not to correct for unequal variances
                      using Welch separate variances T-test. If "auto", it will automatically uses Welch T-test when the sample
                      sizes are unequal. For paired T-tests, this parameter is ignored and no correction is performed. Default
                      is "auto".
   :type correction: Union[bool, str]
   :param confidence: Confidence level between 0 and 1 (exclusive). Default is 0.95.
   :type confidence: float
   :param alternative: The alternative hypothesis. Either "two-sided", "greater", or "less". Default is "two-sided".
   :type alternative: str

   :returns:

             Returns a DataFrame with the following columns:
                - `T`: t-value of the test statistic
                - `dof`: Degrees of freedom
                - `T_critical`: Critical t-value
                - `d`: Cohen's d
                - `d_critical`: Critical value for Cohen's d
                - `g`: Hedges' g
                - `g_critical`: Critical value for Hedges' g
                - `dz`: Cohen's dz (only for paired tests)
                - `dz_critical`: Critical value for Cohen's dz (only for paired tests)
                - `gz`: Hedges' gz (only for paired tests)
                - `gz_critical`: Critical value for Hedges' gz (only for paired tests)
                - `b_critical`: Critical value for the raw mean difference
   :rtype: pd.DataFrame

   :raises ValueError: If for paired tests, n1 != n2 or if r12 is None.

   .. rubric:: Examples

   >>> import numpy as np
   >>> import pingouin as pg
   >>> import critical_es_value as cev
   >>> x = [1,2,3,4,5,6]
   >>> y = [2,2,2,3,3,3]
   >>> t_test_result = pg.ttest(x, y, paired=False).iloc[0]
   >>> cev.critical_for_two_sample_ttest_from_values(
   ...    t=t_test_result["T"],
   ...    n1=len(x),
   ...    n2=len(y),
   ...    dof=t_test_result.dof,
   ...    paired=False,
   ...    std1=np.std(x, ddof=1),
   ...    std2=np.std(y, ddof=1),
   ... ).T
                critical
   T            1.256562
   dof         10.000000
   T_critical   2.228139
   d            0.725476
   d_critical   1.286417
   g            0.669430
   g_critical   1.187035
   b_critical   1.773203


.. py:function:: determine_welch_correction(correction: Union[bool, str], n1: int, n2: int) -> bool

   Determine whether to apply Welch's correction for unequal variances.

   :param correction: If True, always apply Welch's correction.
                      If False, never apply Welch's correction.
                      If "auto", apply Welch's correction only if sample sizes are unequal.
   :type correction: Union[bool, str]
   :param n1: Sample size of group 1.
   :type n1: int
   :param n2: Sample size of group 2.
   :type n2: int

   :returns: Whether to apply Welch's correction.
   :rtype: bool

   :raises ValueError: If `correction` is not one of True, False, or "auto".

   .. rubric:: Examples

   >>> import critical_es_value as cev
   >>> cev.determine_welch_correction("auto", 5, 10)
   True
   >>> cev.determine_welch_correction(True, 5, 10)
   True
   >>> cev.determine_welch_correction(False, 5, 10)
   False


.. py:function:: get_alpha(confidence: float, alternative: str) -> float

   Calculate the significance level (alpha) corresponding to a given confidence level.

   .. math::

       \alpha = \begin{cases}
           1 - \text{conf} & \text{one-sided} \\
           \frac{1 - \text{conf}}{2} & \text{two-sided}
       \end{cases}

   :param confidence: Confidence level between 0 and 1 (exclusive).
   :type confidence: float
   :param alternative: The alternative hypothesis. Either "two-sided", "greater", or "less".
   :type alternative: str

   :returns: The significance level (alpha).
   :rtype: float

   :raises ValueError: If `confidence` is not in (0, 1) or if `alternative` is not one of "two-sided", "greater", or "less".

   .. rubric:: Examples

   >>> import critical_es_value as cev
   >>> cev.get_alpha(0.95, "two-sided")
   0.025
   >>> cev.get_alpha(0.95, "less")
   0.05


.. py:function:: get_bias_correction_factor_J(dof: int) -> numpy.float64

   Calculate the bias correction factor J for Hedges' g.

   .. math::

       J(x) = \frac{\Gamma\left(\frac{x}{2}\right)}{\sqrt{\frac{x}{2}}\Gamma\left(\frac{x-1}{2}\right)}

   :param dof: Degrees of freedom.
   :type dof: int

   :returns: The bias correction factor J.
   :rtype: np.float64

   :raises ValueError: If dof is <= 1.

   .. rubric:: Examples

   >>> import critical_es_value as cev
   >>> cev.get_bias_correction_factor_J(10)
   0.92274560805
   >>> cev.get_bias_correction_factor_J(20)
   0.96194453374


